{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ í›ˆë ¨ ë° ì‹¤í—˜ ì¶”ì \n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì—¬ëŸ¬ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  MLflowë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í—˜ì„ ì¶”ì í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ëª©í‘œ\n",
    "- ë‹¤ì–‘í•œ ML ì•Œê³ ë¦¬ì¦˜ ë¹„êµ\n",
    "- í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”\n",
    "- ì‹¤í—˜ ì¶”ì  ë° ëª¨ë¸ ë²„ì „ ê´€ë¦¬\n",
    "- ìµœì  ëª¨ë¸ ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "C extension: pandas.util not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\workClaude3\\ml-project\\ml-env\\lib\\site-packages\\pandas\\__init__.py:38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m         is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev,  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[1;32mc:\\workClaude3\\ml-project\\ml-env\\lib\\site-packages\\pandas\\compat\\__init__.py:26\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     HAS_PYARROW,\n\u001b[0;32m     29\u001b[0m     pa_version_under10p1,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     pa_version_under21p0,\n\u001b[0;32m     40\u001b[0m )\n",
      "File \u001b[1;32mc:\\workClaude3\\ml-project\\ml-env\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas.util'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\workClaude3\\ml-project\\ml-env\\lib\\site-packages\\pandas\\__init__.py:43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     _module \u001b[38;5;241m=\u001b[39m _err\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC extension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not built. If you want to import \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas from the source directory, you may need to run \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython setup.py build_ext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to build the C extensions first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_err\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     get_option,\n\u001b[0;32m     51\u001b[0m     set_option,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     options,\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: C extension: pandas.util not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "from src.models.trainer import ModelTrainer\n",
    "from src.utils.experiment_tracker import ExperimentTracker\n",
    "from src.utils.config import config\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ (ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©)\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "print(f\"íŠ¹ì„± ë°ì´í„° í˜•íƒœ: {X.shape}\")\n",
    "print(f\"íƒ€ê²Ÿ ë°ì´í„° í˜•íƒœ: {y.shape}\")\n",
    "print(f\"í´ë˜ìŠ¤: {data.target_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶„í• \n",
    "trainer = ModelTrainer()\n",
    "X_train, X_test, y_train, y_test = trainer.prepare_data(X, y)\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {X_train.shape}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}\")\n",
    "print(f\"í´ë˜ìŠ¤ ë¶„í¬ (í›ˆë ¨): {y_train.value_counts().sort_index().tolist()}\")\n",
    "print(f\"í´ë˜ìŠ¤ ë¶„í¬ (í…ŒìŠ¤íŠ¸): {y_test.value_counts().sort_index().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì„± ìŠ¤ì¼€ì¼ë§\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train), \n",
    "    columns=X_train.columns, \n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test), \n",
    "    columns=X_test.columns, \n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(\"âœ… íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ\")\n",
    "print(f\"ìŠ¤ì¼€ì¼ë§ í›„ íŠ¹ì„± í†µê³„:\")\n",
    "print(X_train_scaled.describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì‹¤í—˜ ì¶”ì  ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow ì„¤ì •\n",
    "experiment_tracker = ExperimentTracker(use_mlflow=True, use_wandb=False)\n",
    "\n",
    "# ì‹¤í—˜ ì •ë³´ í™•ì¸\n",
    "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"í˜„ì¬ ì‹¤í—˜: {mlflow.get_experiment_by_name('ml_project_experiments')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ê°œë³„ ëª¨ë¸ í›ˆë ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest ëª¨ë¸ í›ˆë ¨\n",
    "rf_results = trainer.train_model(\n",
    "    algorithm='random_forest',\n",
    "    X_train=X_train_scaled, \n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled, \n",
    "    y_test=y_test,\n",
    "    optimize=True\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸŒ² Random Forest ê²°ê³¼:\")\n",
    "print(f\"ìµœì  íŒŒë¼ë¯¸í„°: {rf_results['best_params']}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {rf_results['test_metrics']['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost ëª¨ë¸ í›ˆë ¨\n",
    "xgb_results = trainer.train_model(\n",
    "    algorithm='xgboost',\n",
    "    X_train=X_train_scaled, \n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled, \n",
    "    y_test=y_test,\n",
    "    optimize=True\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸš€ XGBoost ê²°ê³¼:\")\n",
    "print(f\"ìµœì  íŒŒë¼ë¯¸í„°: {xgb_results['best_params']}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {xgb_results['test_metrics']['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ëª¨ë“  ëª¨ë¸ ë¹„êµ í›ˆë ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  ì„¤ì •ëœ ëª¨ë¸ í›ˆë ¨\n",
    "all_results = trainer.train_all_models(\n",
    "    X_train=X_train_scaled, \n",
    "    y_train=y_train,\n",
    "    X_test=X_test_scaled, \n",
    "    y_test=y_test,\n",
    "    optimize=True\n",
    ")\n",
    "\n",
    "print(\"\\n=== ëª¨ë“  ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ===\")\n",
    "print(f\"í›ˆë ¨ëœ ëª¨ë¸ ìˆ˜: {len(all_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ê²°ê³¼ ë¹„êµ ë° ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”\n",
    "comparison_data = []\n",
    "\n",
    "for algorithm, results in all_results.items():\n",
    "    test_metrics = results['test_metrics']\n",
    "    comparison_data.append({\n",
    "        'Algorithm': algorithm,\n",
    "        'Accuracy': test_metrics['test_accuracy'],\n",
    "        'Precision': test_metrics['test_precision'],\n",
    "        'Recall': test_metrics['test_recall'],\n",
    "        'F1-Score': test_metrics['test_f1']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"=== ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ===\")\n",
    "display(comparison_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„±ëŠ¥ ì§€í‘œ ì‹œê°í™”\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "n_metrics = len(metrics)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    bars = ax.bar(comparison_df['Algorithm'], comparison_df[metric], \n",
    "                  color=['#ff9999', '#66b3ff', '#99ff99', '#ffcc99'][:len(comparison_df)])\n",
    "    \n",
    "    ax.set_title(f'{metric} ë¹„êµ', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(metric, fontsize=12)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # ê°’ ë¼ë²¨ ì¶”ê°€\n",
    "    for bar, value in zip(bars, comparison_df[metric]):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë ˆì´ë” ì°¨íŠ¸ë¡œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "from math import pi\n",
    "\n",
    "# ë ˆì´ë” ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„\n",
    "categories = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "N = len(categories)\n",
    "\n",
    "# ê°ë„ ê³„ì‚°\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]  # ì›ì„ ë‹«ê¸° ìœ„í•´\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "for i, (algorithm, results) in enumerate(all_results.items()):\n",
    "    values = [\n",
    "        results['test_metrics']['test_accuracy'],\n",
    "        results['test_metrics']['test_precision'],\n",
    "        results['test_metrics']['test_recall'],\n",
    "        results['test_metrics']['test_f1']\n",
    "    ]\n",
    "    values += values[:1]  # ì›ì„ ë‹«ê¸° ìœ„í•´\n",
    "    \n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=algorithm, color=colors[i])\n",
    "    ax.fill(angles, values, alpha=0.25, color=colors[i])\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('ëª¨ë¸ ì„±ëŠ¥ ë ˆì´ë” ì°¨íŠ¸', size=16, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ìµœì  ëª¨ë¸ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì  ëª¨ë¸ í™•ì¸\n",
    "best_model = trainer.get_best_model()\n",
    "best_algorithm = comparison_df.iloc[0]['Algorithm']\n",
    "best_results = all_results[best_algorithm]\n",
    "\n",
    "print(f\"ğŸ† ìµœì  ëª¨ë¸: {best_algorithm}\")\n",
    "print(f\"ğŸ“Š í…ŒìŠ¤íŠ¸ ì •í™•ë„: {best_results['test_metrics']['test_accuracy']:.4f}\")\n",
    "print(f\"âš™ï¸ ìµœì  íŒŒë¼ë¯¸í„°: {best_results['best_params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì  ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# ë¶„ë¥˜ ë³´ê³ ì„œ\n",
    "print(\"=== ë¶„ë¥˜ ë³´ê³ ì„œ ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n",
    "\n",
    "# í˜¼ë™ í–‰ë ¬\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=data.target_names, \n",
    "            yticklabels=data.target_names)\n",
    "plt.title(f'{best_algorithm} - í˜¼ë™ í–‰ë ¬')\n",
    "plt.ylabel('ì‹¤ì œ í´ë˜ìŠ¤')\n",
    "plt.xlabel('ì˜ˆì¸¡ í´ë˜ìŠ¤')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì„± ì¤‘ìš”ë„ (ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=importance_df, x='importance', y='feature', palette='viridis')\n",
    "    plt.title(f'{best_algorithm} - íŠ¹ì„± ì¤‘ìš”ë„')\n",
    "    plt.xlabel('ì¤‘ìš”ë„')\n",
    "    plt.ylabel('íŠ¹ì„±')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"=== íŠ¹ì„± ì¤‘ìš”ë„ ìˆœìœ„ ===\")\n",
    "    for idx, row in importance_df.iterrows():\n",
    "        print(f\"{row['feature']}: {row['importance']:.4f}\")\n",
    "else:\n",
    "    print(\"ì„ íƒëœ ëª¨ë¸ì€ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì‹¤í—˜ ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›ˆë ¨ ê²°ê³¼ ì €ì¥\n",
    "trainer.save_results(all_results, 'experiments/training_results.json')\n",
    "\n",
    "# ëª¨ë¸ ë¹„êµ ê²°ê³¼ ì €ì¥\n",
    "comparison_df.to_csv('experiments/model_comparison.csv', index=False)\n",
    "\n",
    "print(\"âœ… ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ\")\n",
    "print(\"ğŸ“ ì €ì¥ ìœ„ì¹˜:\")\n",
    "print(\"   - experiments/training_results.json\")\n",
    "print(\"   - experiments/model_comparison.csv\")\n",
    "print(\"   - models/ (ê° ëª¨ë¸ì˜ .joblib íŒŒì¼)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. MLflow UI í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MLflow ì‹¤í—˜ ì¶”ì  ===\")\n",
    "print(\"ì‹¤í—˜ ê²°ê³¼ë¥¼ í™•ì¸í•˜ë ¤ë©´ í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:\")\n",
    "print(\"\")\n",
    "print(\"cd ml-project\")\n",
    "print(\"mlflow ui\")\n",
    "print(\"\")\n",
    "print(\"ê·¸ í›„ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5000 ìœ¼ë¡œ ì ‘ì†í•˜ì„¸ìš”.\")\n",
    "print(\"\")\n",
    "print(\"MLflow UIì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì •ë³´:\")\n",
    "print(\"- ğŸ“Š ê° ì‹¤í—˜ì˜ íŒŒë¼ë¯¸í„°ì™€ ë©”íŠ¸ë¦­\")\n",
    "print(\"- ğŸ“ˆ ë©”íŠ¸ë¦­ ë¹„êµ ì°¨íŠ¸\")\n",
    "print(\"- ğŸ”§ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸\")\n",
    "print(\"- ğŸ“ ì‹¤í—˜ ë…¸íŠ¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ëª¨ë¸ í›ˆë ¨ ìš”ì•½ ===\")\n",
    "print(f\"ğŸ¯ í›ˆë ¨ëœ ëª¨ë¸ ìˆ˜: {len(all_results)}\")\n",
    "print(f\"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_algorithm}\")\n",
    "print(f\"ğŸ“Š ìµœê³  ì •í™•ë„: {comparison_df.iloc[0]['Accuracy']:.4f}\")\n",
    "print(f\"ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”: âœ… ì™„ë£Œ\")\n",
    "print(f\"ğŸ“ˆ ì‹¤í—˜ ì¶”ì : âœ… MLflow ê¸°ë¡\")\n",
    "\n",
    "print(\"\\n=== ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­ ===\")\n",
    "print(\"1. ğŸ” ëª¨ë¸ í•´ì„ ë° ì„¤ëª…ê°€ëŠ¥ì„± ë¶„ì„\")\n",
    "print(\"2. ğŸ§ª êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ ì•ˆì •ì„± ê²€ì¦\")\n",
    "print(\"3. ğŸš€ ëª¨ë¸ ë°°í¬ ì¤€ë¹„\")\n",
    "print(\"4. ğŸ“Š A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„\")\n",
    "print(\"5. ğŸ”„ ëª¨ë¸ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•\")\n",
    "\n",
    "print(\"\\n=== ì„±ëŠ¥ ê°œì„  ì•„ì´ë””ì–´ ===\")\n",
    "print(\"- ğŸ”§ ë” ë§ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•© ì‹œë„\")\n",
    "print(\"- ğŸ¯ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±\")\n",
    "print(\"- ğŸ“Š ë” ë§ì€ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§\")\n",
    "print(\"- ğŸ”„ êµì°¨ ê²€ì¦ ì „ëµ ê°œì„ \")\n",
    "print(\"- ğŸ“ˆ ë‹¤ë¥¸ í‰ê°€ ì§€í‘œ ê³ ë ¤\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
