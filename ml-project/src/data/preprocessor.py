"""S&P 500 ë°ì´í„° ì „ì²˜ë¦¬ ëª¨ë“ˆ"""

import pandas as pd
import numpy as np
from scipy import stats
from typing import Dict, Tuple, List
import warnings

warnings.filterwarnings('ignore')

class SP500Preprocessor:
    """S&P 500 ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”"""
        self.scaler = None
        self.outlier_bounds = {}
        
    def load_data(self, file_path: str) -> pd.DataFrame:
        """CSV íŒŒì¼ì—ì„œ S&P 500 ë°ì´í„° ë¡œë“œ
        
        Args:
            file_path: CSV íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ë¡œë“œëœ DataFrame
        """
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        return df
    
    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê¸°ë³¸ ë°ì´í„° ì •ì œ
        
        Args:
            df: ì›ë³¸ DataFrame
            
        Returns:
            ì •ì œëœ DataFrame
        """
        df_clean = df.copy()
        
        # ì»¬ëŸ¼ëª… ì˜ì–´ë¡œ ë³€ê²½
        column_mapping = {
            'ë‚ ì§œ': 'Date',
            'ì¢…ê°€': 'Close',
            'ì‹œê°€': 'Open',
            'ê³ ê°€': 'High',
            'ì €ê°€': 'Low',
            'ê±°ë˜ëŸ‰': 'Volume',
            'ë³€ë™ %': 'Change_Pct'
        }
        
        df_clean = df_clean.rename(columns=column_mapping)
        
        # ë‚ ì§œ ì²˜ë¦¬
        df_clean['Date'] = df_clean['Date'].str.replace(' ', '').str.replace('-', '-')
        df_clean['Date'] = pd.to_datetime(df_clean['Date'], format='%Y-%m-%d')
        
        # ìˆ˜ì¹˜ ì»¬ëŸ¼ ì²˜ë¦¬
        numeric_columns = ['Open', 'High', 'Low', 'Close']
        for col in numeric_columns:
            df_clean[col] = df_clean[col].str.replace(',', '').astype(float)
        
        # ë³€ë™ë¥  ì²˜ë¦¬
        df_clean['Change_Pct'] = df_clean['Change_Pct'].str.replace('%', '').astype(float)
        
        # Volume ì²˜ë¦¬ (ë¹ˆ ë¬¸ìì—´ì„ NaNìœ¼ë¡œ)
        df_clean['Volume'] = df_clean['Volume'].replace('', np.nan)
        
        # ë‚ ì§œìˆœ ì •ë ¬
        df_clean = df_clean.sort_values('Date').reset_index(drop=True)
        
        return df_clean
    
    def handle_missing_values(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        
        Args:
            df: DataFrame
            
        Returns:
            ê²°ì¸¡ì¹˜ ì²˜ë¦¬ëœ DataFrame
        """
        df_filled = df.copy()
        
        # Volumeì´ ëª¨ë‘ ê²°ì¸¡ì¹˜ì¸ ê²½ìš° ì»¬ëŸ¼ ì œê±°
        if df_filled['Volume'].isnull().all():
            df_filled = df_filled.drop('Volume', axis=1)
        else:
            # ë¶€ë¶„ì  ê²°ì¸¡ì¹˜ëŠ” ë³´ê°„ë²• ì‚¬ìš©
            df_filled['Volume'] = df_filled['Volume'].interpolate()
        
        return df_filled
    
    def detect_outliers_iqr(self, data: pd.Series, multiplier: float = 1.5) -> Tuple[pd.Index, float, float]:
        """IQR ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€
        
        Args:
            data: ë°ì´í„° ì‹œë¦¬ì¦ˆ
            multiplier: IQR ë°°ìˆ˜
            
        Returns:
            ì´ìƒì¹˜ ì¸ë±ìŠ¤, í•˜í•œê°’, ìƒí•œê°’
        """
        Q1 = data.quantile(0.25)
        Q3 = data.quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - multiplier * IQR
        upper_bound = Q3 + multiplier * IQR
        
        outliers_mask = (data < lower_bound) | (data > upper_bound)
        outliers_idx = data[outliers_mask].index
        
        return outliers_idx, lower_bound, upper_bound
    
    def detect_outliers_zscore(self, data: pd.Series, threshold: float = 3) -> pd.Index:
        """Z-score ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€
        
        Args:
            data: ë°ì´í„° ì‹œë¦¬ì¦ˆ
            threshold: Z-score ì„ê³„ê°’
            
        Returns:
            ì´ìƒì¹˜ ì¸ë±ìŠ¤
        """
        z_scores = np.abs(stats.zscore(data.dropna()))
        outliers_mask = z_scores > threshold
        outliers_idx = data.dropna().index[outliers_mask]
        
        return outliers_idx
    
    def calculate_rsi(self, prices: pd.Series, window: int = 14) -> pd.Series:
        """RSI ê³„ì‚°
        
        Args:
            prices: ê°€ê²© ì‹œë¦¬ì¦ˆ
            window: ê³„ì‚° ìœˆë„ìš°
            
        Returns:
            RSI ì‹œë¦¬ì¦ˆ
        """
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def add_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
        
        Args:
            df: DataFrame
            
        Returns:
            ê¸°ìˆ ì  ì§€í‘œê°€ ì¶”ê°€ëœ DataFrame
        """
        df_tech = df.copy()
        
        # ê¸°ë³¸ ê³„ì‚°
        df_tech['Daily_Return'] = df_tech['Close'].pct_change() * 100
        df_tech['Price_Range'] = df_tech['High'] - df_tech['Low']
        df_tech['Price_Range_Pct'] = (df_tech['Price_Range'] / df_tech['Close']) * 100
        
        # ì´ë™í‰ê· 
        df_tech['SMA_5'] = df_tech['Close'].rolling(window=5).mean()
        df_tech['SMA_10'] = df_tech['Close'].rolling(window=10).mean()
        df_tech['SMA_20'] = df_tech['Close'].rolling(window=20).mean()
        
        # ì§€ìˆ˜ì´ë™í‰ê· 
        df_tech['EMA_12'] = df_tech['Close'].ewm(span=12).mean()
        df_tech['EMA_26'] = df_tech['Close'].ewm(span=26).mean()
        
        # MACD
        df_tech['MACD'] = df_tech['EMA_12'] - df_tech['EMA_26']
        df_tech['MACD_Signal'] = df_tech['MACD'].ewm(span=9).mean()
        df_tech['MACD_Histogram'] = df_tech['MACD'] - df_tech['MACD_Signal']
        
        # RSI
        df_tech['RSI'] = self.calculate_rsi(df_tech['Close'])
        
        # ë³¼ë¦°ì € ë°´ë“œ
        df_tech['BB_Middle'] = df_tech['Close'].rolling(window=20).mean()
        bb_std = df_tech['Close'].rolling(window=20).std()
        df_tech['BB_Upper'] = df_tech['BB_Middle'] + (bb_std * 2)
        df_tech['BB_Lower'] = df_tech['BB_Middle'] - (bb_std * 2)
        df_tech['BB_Width'] = df_tech['BB_Upper'] - df_tech['BB_Lower']
        df_tech['BB_Position'] = (df_tech['Close'] - df_tech['BB_Lower']) / (df_tech['BB_Upper'] - df_tech['BB_Lower'])
        
        # ë³€ë™ì„±
        df_tech['Volatility_10'] = df_tech['Daily_Return'].rolling(window=10).std()
        df_tech['Volatility_20'] = df_tech['Daily_Return'].rolling(window=20).std()
        
        # ëª¨ë©˜í…€
        df_tech['Momentum_5'] = df_tech['Close'] / df_tech['Close'].shift(5) - 1
        df_tech['Momentum_10'] = df_tech['Close'] / df_tech['Close'].shift(10) - 1
        
        # ì§€ì§€/ì €í•­
        df_tech['Support'] = df_tech['Low'].rolling(window=20).min()
        df_tech['Resistance'] = df_tech['High'].rolling(window=20).max()
        
        # ì‹œê°„ íŠ¹ì„±
        df_tech['Day_of_Week'] = df_tech['Date'].dt.dayofweek
        df_tech['Month'] = df_tech['Date'].dt.month
        df_tech['Quarter'] = df_tech['Date'].dt.quarter
        
        return df_tech
    
    def get_feature_groups(self) -> Dict[str, List[str]]:
        """íŠ¹ì„± ê·¸ë£¹ ì •ì˜
        
        Returns:
            íŠ¹ì„± ê·¸ë£¹ ë”•ì…”ë„ˆë¦¬
        """
        return {
            'price_features': ['Open', 'High', 'Low', 'Close'],
            'return_features': ['Daily_Return', 'Change_Pct'],
            'sma_features': ['SMA_5', 'SMA_10', 'SMA_20'],
            'ema_features': ['EMA_12', 'EMA_26'],
            'technical_features': ['RSI', 'MACD', 'MACD_Signal', 'MACD_Histogram'],
            'bollinger_features': ['BB_Upper', 'BB_Middle', 'BB_Lower', 'BB_Width', 'BB_Position'],
            'volatility_features': ['Volatility_10', 'Volatility_20', 'Price_Range', 'Price_Range_Pct'],
            'momentum_features': ['Momentum_5', 'Momentum_10'],
            'support_resistance': ['Support', 'Resistance'],
            'time_features': ['Day_of_Week', 'Month', 'Quarter']
        }
    
    def preprocess_pipeline(self, file_path: str, save_path: str = None) -> pd.DataFrame:
        """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            file_path: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
            save_path: ì €ì¥í•  ê²½ë¡œ (ì„ íƒì‚¬í•­)
            
        Returns:
            ì „ì²˜ë¦¬ëœ DataFrame
        """
        print("ğŸ”„ S&P 500 ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
        
        # 1. ë°ì´í„° ë¡œë“œ
        print("1ï¸âƒ£ ë°ì´í„° ë¡œë“œ ì¤‘...")
        df = self.load_data(file_path)
        print(f"   ì›ë³¸ ë°ì´í„°: {df.shape}")
        
        # 2. ë°ì´í„° ì •ì œ
        print("2ï¸âƒ£ ë°ì´í„° ì •ì œ ì¤‘...")
        df_clean = self.clean_data(df)
        
        # 3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        print("3ï¸âƒ£ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì¤‘...")
        df_filled = self.handle_missing_values(df_clean)
        
        # 4. ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
        print("4ï¸âƒ£ ê¸°ìˆ ì  ì§€í‘œ ìƒì„± ì¤‘...")
        df_final = self.add_technical_indicators(df_filled)
        print(f"   ìµœì¢… ë°ì´í„°: {df_final.shape}")
        
        # 5. ì´ìƒì¹˜ íƒì§€ ë° ê¸°ë¡
        print("5ï¸âƒ£ ì´ìƒì¹˜ íƒì§€ ì¤‘...")
        outliers_idx, lower_bound, upper_bound = self.detect_outliers_iqr(df_final['Daily_Return'])
        self.outlier_bounds['Daily_Return'] = (lower_bound, upper_bound)
        print(f"   ì¼ì¼ ìˆ˜ìµë¥  ì´ìƒì¹˜: {len(outliers_idx)}ê°œ ({len(outliers_idx)/len(df_final)*100:.1f}%)")
        
        # 6. ì €ì¥
        if save_path:
            print("6ï¸âƒ£ ë°ì´í„° ì €ì¥ ì¤‘...")
            df_final.to_csv(save_path, index=False, encoding='utf-8-sig')
            print(f"   ì €ì¥ ì™„ë£Œ: {save_path}")
        
        print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        return df_final
    
    def get_analysis_summary(self, df: pd.DataFrame) -> Dict:
        """ë°ì´í„° ë¶„ì„ ìš”ì•½ ì •ë³´ ìƒì„±
        
        Args:
            df: ë¶„ì„í•  DataFrame
            
        Returns:
            ë¶„ì„ ìš”ì•½ ë”•ì…”ë„ˆë¦¬
        """
        summary = {
            'data_info': {
                'shape': df.shape,
                'date_range': {
                    'start': df['Date'].min(),
                    'end': df['Date'].max(),
                    'days': (df['Date'].max() - df['Date'].min()).days,
                    'trading_days': len(df)
                }
            },
            'price_stats': {
                'min_price': df['Close'].min(),
                'max_price': df['Close'].max(),
                'avg_price': df['Close'].mean(),
                'current_price': df['Close'].iloc[-1]
            },
            'return_stats': {
                'avg_daily_return': df['Daily_Return'].mean(),
                'volatility': df['Daily_Return'].std(),
                'max_gain': df['Daily_Return'].max(),
                'max_loss': df['Daily_Return'].min(),
                'sharpe_ratio': (df['Daily_Return'].mean() * 252) / (df['Daily_Return'].std() * np.sqrt(252))
            },
            'technical_status': {
                'current_rsi': df['RSI'].iloc[-1],
                'current_bb_position': df['BB_Position'].iloc[-1],
                'current_volatility': df['Volatility_10'].iloc[-1],
                'trend_vs_sma20': 'up' if df['Close'].iloc[-1] > df['SMA_20'].iloc[-1] else 'down',
                'macd_signal': 'bullish' if df['MACD'].iloc[-1] > df['MACD_Signal'].iloc[-1] else 'bearish'
            }
        }
        
        return summary

# ì „ì—­ ì „ì²˜ë¦¬ê¸° ì¸ìŠ¤í„´ìŠ¤
preprocessor = SP500Preprocessor()